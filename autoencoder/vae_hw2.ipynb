{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c0982ce0",
      "metadata": {
        "id": "c0982ce0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as functional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "92571e8e",
      "metadata": {
        "id": "92571e8e"
      },
      "outputs": [],
      "source": [
        "# Создаём VAE\n",
        "class VAE(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 7), \n",
        "            nn.ReLU(),\n",
        "            Compress())\n",
        "        \n",
        "        # Матиматическое ожидание\n",
        "        self.fc_mu = nn.Linear(64, 64)\n",
        "        # Дисперсия  \n",
        "        self.fc_logvar = nn.Linear(64, 64) \n",
        "     \n",
        "        # Decoder:\n",
        "        self.decoder = nn.Sequential(\n",
        "            Decompress(),\n",
        "            nn.ConvTranspose2d(64, 32, 7), \n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()) # get probability\n",
        "        \n",
        "\n",
        "    # reparametrization trick:\n",
        "    def sample(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        e = torch.randn_like(std)\n",
        "        z = mu + (std * e)\n",
        "        return z\n",
        "    \n",
        "\n",
        "    def generateExample(self, num_examples):\n",
        "        # x must be 64, 1, 1 tensor\n",
        "        mu = torch.zeros(num_examples, 64)\n",
        "        logvar = torch.ones(num_examples, 64)\n",
        "        z = self.sample(mu, logvar)\n",
        "        return self.decoder(z)\n",
        "    \n",
        "    \n",
        "\n",
        "    def forward(self, x): # x - batch of images\n",
        "        print(f\"Before encoding: {x.shape}\")\n",
        "        x = self.encoder(x)\n",
        "        print(f\"After encoding: {x.shape}\")\n",
        "        \n",
        "        mu = self.fc_mu(x)\n",
        "        mu = torch.zeros(10, 64)\n",
        "        print(f\"Mean (mu) Shape: {mu.shape}\")\n",
        "        logvar = self.fc_logvar(x)\n",
        "        logvar = torch.ones(10, 64)\n",
        "        print(f\"Log Variance Shape: {logvar.shape}\")\n",
        "        \n",
        "        z = self.sample(mu, logvar)\n",
        "        print(f\"Z Shape: {z.shape}\")\n",
        "        \n",
        "        recon_x = self.decoder(z)\n",
        "        #mu 0 logvar 1 for reconstrion\n",
        "        print(f\"Reconstructed x After Decoding: {recon_x.shape}\")\n",
        "        return recon_x, mu, logvar\n",
        "\n",
        "    \n",
        "class Compress(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1) # растягиваем тензор\n",
        "    \n",
        "    \n",
        "class Decompress(nn.Module):\n",
        "    def forward(self, input, size=28*28):\n",
        "        print(input.view(input.size(0), input.size(1), 1, 1).shape)\n",
        "        return input.view(input.size(0), input.size(1), 1, 1)\n",
        "\n",
        "def loss_fn(recon_x, x, mu, logvar):\n",
        "    \n",
        "    # squared error MSELoss\n",
        "    loss = functional.mse_loss(recon_x, x, reduction=\"sum\")\n",
        "    KL_Div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return loss + KL_Div"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e61d472c",
      "metadata": {
        "id": "e61d472c"
      },
      "outputs": [],
      "source": [
        "# Получаем наш MNIST\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "dataset = datasets.MNIST(\n",
        "    root = \"data\",\n",
        "    download = True,\n",
        "    transform = transform\n",
        "    )\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "# Создаём DATA LOADER\n",
        "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bbb1bdc7",
      "metadata": {
        "id": "bbb1bdc7"
      },
      "outputs": [],
      "source": [
        "# Показываем изображения\n",
        "def showImage(img, img_recon, epoch):\n",
        "    \n",
        "    # unnormalize\n",
        "    fig = plt.figure()\n",
        "    fig.add_subplot(1, 2, 1)\n",
        "    \n",
        "    img = img.numpy()\n",
        "    plt.title(label=\"Original Epoch: #\"+str(epoch))\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "    fig.add_subplot(1, 2, 2)\n",
        "    \n",
        "    img_recon = img_recon.numpy()\n",
        "    plt.title(label=\"Reconstruction Epoch: #\"+str(epoch))\n",
        "    plt.imshow(np.transpose(img_recon, (1, 2, 0)))\n",
        "    plt.show(block=True)\n",
        "    \n",
        "def showExample(img):\n",
        "    \n",
        "    # unnormalize\n",
        "    fig = plt.figure()\n",
        "    fig.add_subplot(1, 2, 1)\n",
        "    img = img.numpy()\n",
        "    plt.title(label=\"Generated Example\")\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "    plt.show(block=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "576d1de1",
      "metadata": {
        "id": "576d1de1"
      },
      "outputs": [],
      "source": [
        "model = VAE()\n",
        "\n",
        "learning_rate = .001  # шаг спуска - 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "epochs = 10\n",
        "running_loss = 0.0\n",
        "\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-----------------------------------\")\n",
        "    for idx, (images, _) in enumerate(train_dataloader):\n",
        "        \n",
        "        images = images\n",
        "        recon_x, mu, logvar = model(images)\n",
        "        loss = loss_fn(recon_x, images, mu, logvar)\n",
        "        \n",
        "        optimizer.zero_grad()   # обнулим градиенты\n",
        "        loss.backward()         # calc gradients\n",
        "        optimizer.step()        # do step of grads\n",
        "        \n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if idx % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            \n",
        "            #output the original image and the reconstructed image\n",
        "            showImage( torchvision.utils.make_grid(images), torchvision.utils.make_grid(recon_x.to(\"cpu\")), t+1 )        \n",
        "            \n",
        "            print('loss: %.3f' %(running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "    \n",
        "print(\"Generating a random example...\")\n",
        "num_examples = 10\n",
        "                      \n",
        "\n",
        "example = model.generateExample(num_examples)\n",
        "showExample(torchvision.utils.make_grid(example))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
